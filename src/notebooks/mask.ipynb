{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7751feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "023312a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[0, 1, 2, 3, 4, 0, 1, 2]], dtype=torch.int32)\n",
      "tensor([[[ True, False, False, False, False,  True, False, False],\n",
      "         [ True,  True, False, False, False,  True,  True, False],\n",
      "         [ True,  True,  True, False, False,  True,  True,  True],\n",
      "         [ True,  True,  True,  True, False,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True, False, False, False, False,  True, False, False],\n",
      "         [ True,  True, False, False, False,  True,  True, False],\n",
      "         [ True,  True,  True, False, False,  True,  True,  True]]])\n",
      "tensor([[1, 1, 1, 1, 1, 2, 2, 2]])\n",
      "tensor([[[0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 0, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 0, 0, 1],\n",
      "         [1, 1, 1, 1, 1, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "q_len = 8\n",
    "k_len = 8\n",
    "\n",
    "mask = torch.triu(torch.ones((q_len, k_len), dtype=int), diagonal=1)\n",
    "\n",
    "print(mask)\n",
    "\n",
    "position_ids = torch.tensor([[0, 1, 2, 3, 4, 0, 1, 2]]).int()\n",
    "\n",
    "print(position_ids)\n",
    "\n",
    "print((position_ids.unsqueeze(-1) >= position_ids.unsqueeze(-2)))\n",
    "\n",
    "# find all indices where position_ids == 0\n",
    "starts = (position_ids == 0).to(torch.long)\n",
    "segment_ids = starts.cumsum(dim=1)\n",
    "\n",
    "print(segment_ids)\n",
    "\n",
    "mask = mask | (segment_ids.unsqueeze(-1) != segment_ids.unsqueeze(-2))\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd9ec546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, -1, -1, -1, -1,  5, -1, -1],\n",
      "        [ 0, -1, -1, -1, -1, -1,  6, -1]])\n",
      "tensor([[0, 0, 0, 0, 0, 5, 5, 5],\n",
      "        [0, 0, 0, 0, 0, 0, 6, 6]])\n",
      "tensor([[0, 1, 2, 3, 4, 0, 1, 2],\n",
      "        [0, 1, 2, 3, 4, 5, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "])\n",
    "eos_token_id = 1\n",
    "pad_token_id = 2\n",
    "\n",
    "def make_position_ids(input_ids: torch.Tensor, eos_token_id: int, pad_token_id: int | None = None):\n",
    "    \"\"\"\n",
    "    input_ids: (B, S) LongTensor\n",
    "    Reset rule: positions start at 0; after every EOS token, the *next* token restarts at 0.\n",
    "    pad handling: if pad_token_id is provided, pad positions are set to 0.\n",
    "    \"\"\"\n",
    "    B, S = input_ids.shape\n",
    "    device = input_ids.device\n",
    "\n",
    "    # segment starts: col 0, and any position whose *previous* token was EOS\n",
    "    starts = torch.zeros_like(input_ids, dtype=torch.bool)\n",
    "    starts[:, 0] = True\n",
    "    starts[:, 1:] = (input_ids[:, :-1] == eos_token_id)\n",
    "\n",
    "    # index grid\n",
    "    idx = torch.arange(S, device=device).unsqueeze(0).expand(B, -1)\n",
    "\n",
    "    # index of the most recent segment start, per position (running max trick)\n",
    "    last_start_idx = torch.where(starts, idx, torch.full_like(idx, -1))\n",
    "    print(last_start_idx)\n",
    "    last_start_idx = torch.cummax(last_start_idx, dim=1).values  # (B, S)\n",
    "    print(last_start_idx)\n",
    "\n",
    "    # distance since last start â†’ 0,1,2,... within each segment\n",
    "    position_ids = (idx - last_start_idx).to(torch.long)\n",
    "\n",
    "    # optional: zero-out pads\n",
    "    if pad_token_id is not None:\n",
    "        position_ids = position_ids.masked_fill(input_ids == pad_token_id, 0)\n",
    "\n",
    "    return position_ids\n",
    "\n",
    "print(make_position_ids(input_ids, eos_token_id, pad_token_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tooluse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
