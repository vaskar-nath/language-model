{
    "model_configs": {
        "vocab_size": 10000,
        "context_length": 100000,
        "d_model": 512,
        "num_layers": 32,
        "num_heads": 32,
        "d_ff": 2048,
        "attn_pdrop": 0.1,
        "residual_pdrop": 0.1
    },
    "learning_rate": {
        "max_learning_rate": 6e-4,
        "min_learning_rate": 3e-4,
        "warmup_iters": 1000,
        "cosine_cycle_iters": 200000
    },
    "weight_decay": 0.1,
    "betas": [0.9, 0.95],
    "eps": 1e-8,
    "num_epochs": 1,
    "batch_size": 64,
    "val_interval": 1000,
    "log_interval": 1,
    "save_interval": 1000,
    "save_dir": "/mnt/efs/vaskarnath/practice/owt_lm_contrastive_v2",
    "train_steps": 200000,
    "val_steps": 500,
    "vocab_filepath": "/mnt/efs/vaskarnath/practice/language-model/tokenizers/owt_train_tokenizer/vocab.json",
    "merges_filepath": "/mnt/efs/vaskarnath/practice/language-model/tokenizers/owt_train_tokenizer/merges.txt",
    "pretrained_tokenizer": "openai-community/gpt2-xl",
    "special_tokens": ["<|endoftext|>"],
    "train_dataset_path": "/mnt/efs/vaskarnath/practice/language-model/data/owt_train.txt",
    "val_dataset_path": "/mnt/efs/vaskarnath/practice/language-model/data/owt_valid.txt",
    "gradient_clipping": 1.0,
    "train_input_ids": "/mnt/efs/vaskarnath/practice/language-model/data/owt_train_input_ids.npy",
    "val_input_ids": "/mnt/efs/vaskarnath/practice/language-model/data/owt_valid_input_ids.npy",
    "contrastive_loss": {
        "use_contrastive_loss": true,
        "n_samples": 16,
        "beta": 0.5
    }
}